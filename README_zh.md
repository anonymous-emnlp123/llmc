# llmcï¼šå‘ç²¾ç¡®é«˜æ•ˆçš„å¤§å‹è¯­è¨€æ¨¡å‹å‹ç¼©è¿ˆè¿›

<img src="./imgs/llmc.png" alt="llmc" style="zoom:35%;" />

**\[ [English](https://github.com/ModelTC/llmc?tab=readme-ov-file#llmc-towards-accurate-and-efficient-llm-compression) | ä¸­æ–‡ | [æ—¥æœ¬èª](README_ja.md) \]**

**llmc** æ˜¯ä¸€ä¸ªå³æ’å³ç”¨çš„å·¥å…·ï¼Œæ—¨åœ¨é€šè¿‡æœ€å…ˆè¿›çš„å‹ç¼©ç®—æ³•è¿›è¡Œå¤§å‹è¯­è¨€æ¨¡å‹çš„å‹ç¼©ï¼Œä»¥æé«˜æ•ˆç‡å¹¶å‡å°æ¨¡å‹å¤§å°ï¼ŒåŒæ—¶ä¸ç‰ºç‰²æ€§èƒ½ã€‚

**æ–‡æ¡£**åœ¨[è¿™é‡Œ](https://llmc-test.readthedocs.io/en/latest/).


## çªå‡ºç‰¹æ€§

- é‡åŒ–å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¦‚ Llama2-70Bã€OPT-175Bï¼Œå¹¶åœ¨ä»…ä¸€ä¸ª A100/H100/H800 GPUä¸Šè¯„ä¼°å…¶ PPLğŸ’¥ã€‚
- ä¸ºç”¨æˆ·æä¾›é€‰æ‹©çš„æœ€æ–°çš„[ä¸åŸè®ºæ–‡ä»£ç ä»“åº“ç²¾åº¦å¯¹é½](benchmark/align.md)çš„å‹ç¼©ç®—æ³•ï¼Œå¹¶ä¸”ç”¨æˆ·å¯ä»¥åœ¨ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ä¸Šä¾æ¬¡ä½¿ç”¨å¤šä¸ªç®—æ³•ğŸ’¥ã€‚
- ç”±æˆ‘ä»¬å·¥å…·é€šè¿‡ç‰¹å®šå‹ç¼©ç®—æ³•å¯¼å‡ºçš„è½¬æ¢æ¨¡å‹ï¼ˆ`save_trans`æ¨¡å¼åœ¨`quant`éƒ¨åˆ†çš„[é…ç½®](#é…ç½®)ï¼‰å¯ä»¥é€šè¿‡å¤šä¸ªåç«¯è¿›è¡Œç®€å•é‡åŒ–ï¼Œå¾—åˆ°ç»è¿‡ç‰¹å®šå‹ç¼©ç®—æ³•ä¼˜åŒ–çš„æ¨¡å‹ï¼Œç›¸åº”çš„åç«¯å¯ä»¥è¿›è¡Œæ¨æ–­ğŸ’¥ã€‚
- æˆ‘ä»¬çš„å‹ç¼©æ¨¡å‹ï¼ˆ`save_lightllm`æ¨¡å¼åœ¨`quant`éƒ¨åˆ†çš„\[é…ç½®\](#é…ç½®)ï¼‰å…·æœ‰è¾ƒä½çš„å†…å­˜å ç”¨ï¼Œå¯ä»¥ç›´æ¥é€šè¿‡[Lightllm](https://github.com/ModelTC/lightllm)è¿›è¡Œæ¨æ–­ğŸ’¥ã€‚

## ä½¿ç”¨æ–¹å¼

1. å…‹éš†æ­¤ä»“åº“å¹¶å®‰è£…åŒ…ï¼š

   ```shell
   # å®‰è£…åŒ…
   cd llmc
   pip install -r requirements.txt
   ```

2. å‡†å¤‡æ¨¡å‹å’Œæ•°æ®ã€‚

   ```shell
   # åœ¨ä»huggingfaceä¸‹è½½LLMåï¼ŒæŒ‰ä»¥ä¸‹æ–¹å¼å‡†å¤‡æ ¡å‡†å’Œè¯„ä¼°æ•°æ®ï¼š
   cd tools
   python download_calib_dataset.py --save_path [æ ¡å‡†æ•°æ®è·¯å¾„]
   python download_eval_dataset.py --save_path [è¯„ä¼°æ•°æ®è·¯å¾„]
   ```

3. é€‰æ‹©ä¸€ä¸ªç®—æ³•æ¥é‡åŒ–ä½ çš„æ¨¡å‹ï¼š

   ```shell
   # è¿™æ˜¯ä¸€ä¸ªå…³äº Awq çš„ä¾‹å­ï¼š
   cd scripts
   # ä¿®æ”¹ bash æ–‡ä»¶ä¸­çš„ llmc è·¯å¾„ï¼Œ``llmc_path``ã€‚ä½ ä¹Ÿå¯ä»¥é€‰æ‹©``llmc/configs/quantization/Awq/``ä¸­çš„ä¸€ä¸ªé…ç½®æ¥é‡åŒ–ä½ çš„æ¨¡å‹ï¼Œæˆ–è€…é€šè¿‡æ›´æ”¹``--config``å‚æ•°åœ¨ run_awq_llama.sh ä¸­ä½¿ç”¨æˆ‘ä»¬æä¾›çš„é…ç½®ã€‚
   bash run_awq_llama.sh
   ```

## é…ç½®

ä¸ºäº†å¸®åŠ©ç”¨æˆ·è®¾è®¡ä»–ä»¬çš„é…ç½®ï¼Œæˆ‘ä»¬ç°åœ¨è§£é‡Šæˆ‘ä»¬åœ¨`llmc/configs/`ä¸‹æä¾›çš„æ‰€æœ‰é…ç½®ä¸­çš„ä¸€äº›é€šç”¨é…ç½®ï¼š

- `model`:

  ```yaml
  model:
      # ç”¨``llmc/models/*.py``ä¸­çš„ç±»åæ›¿æ¢ã€‚
      type: Llama
      # ç”¨ä½ çš„æ¨¡å‹è·¯å¾„æ›¿æ¢ã€‚
      path: model path
      torch_dtype: auto
  ```

- `calib`:

  ```yaml
  # æ³¨æ„ï¼šä¸€äº›ç®—æ³•ä¸éœ€è¦``calib``ï¼Œå¦‚ naive... æ‰€ä»¥ï¼Œä½ å¯ä»¥ç§»é™¤è¿™éƒ¨åˆ†ã€‚
  calib:
      # ç”¨ä¹‹å‰ä¸‹è½½çš„æ ¡å‡†æ•°æ®åç§°æ›¿æ¢ï¼Œä¾‹å¦‚ï¼Œpilevalã€c4ã€wikitext2 æˆ– ptbã€‚
      name: pileval
      download: False
      # ç”¨ä¹‹å‰ä¸‹è½½çš„æŸä¸ªæ ¡å‡†æ•°æ®çš„è·¯å¾„æ›¿æ¢ï¼Œä¾‹å¦‚ï¼Œpilevalã€c4ã€wikitext2 æˆ– ptbã€‚
      path: calib data path
      n_samples: 128
      bs: -1
      seq_len: 512
      # ç”¨``llmc/data/dataset/specified_preproc.py``ä¸­çš„å‡½æ•°åç§°æ›¿æ¢ã€‚
      preproc: general
      seed: *seed
  ```

- `eval`:

  ```yaml
  # å¦‚æœä½ æƒ³è¯„ä¼°ä½ çš„é¢„è®­ç»ƒ/è½¬æ¢/å‡é‡åŒ–æ¨¡å‹çš„ PPLã€‚
  eval:
      # ä½ å¯ä»¥è¯„ä¼°é¢„è®­ç»ƒã€è½¬æ¢ã€å‡é‡åŒ–æ¨¡å‹ï¼Œå¹¶è®¾ç½®ä½ æƒ³è¦è¯„ä¼°çš„ä½ç½®ã€‚
      eval_pos: [pretrain, transformed, fake_quant]
      # ç”¨ä¹‹å‰ä¸‹è½½çš„è¯„ä¼°æ•°æ®çš„åç§°æ›¿æ¢ï¼Œä¾‹å¦‚ï¼Œc4ã€wikitext2ã€ptb æˆ– [c4, wikitext2]ã€‚
      name: wikitext2
      download: False
      path: eval data path
      # å¯¹äº 70B æ¨¡å‹è¯„ä¼°ï¼Œbs å¯ä»¥è®¾ç½®ä¸º 20ï¼Œå¹¶ä¸”å¯ä»¥å°† inference_per_block è®¾ç½®ä¸º Trueã€‚
      # å¯¹äº 7B / 13B æ¨¡å‹è¯„ä¼°ï¼Œbs å¯ä»¥è®¾ç½®ä¸º 1ï¼Œå¹¶ä¸”å¯ä»¥å°† inference_per_block è®¾ç½®ä¸º Falseã€‚
      bs: 1
      inference_per_block: False
      seq_len: 2048
  ```

- `save`:

  ```yaml
  save:
      # å¦‚æœ``save_trans``ä¸º Trueï¼Œè¿™æ„å‘³ç€ä½ æƒ³è¦å¯¼å‡ºè½¬æ¢æ¨¡å‹ï¼Œä¾‹å¦‚ï¼Œå‚æ•°ä¿®æ”¹çš„æ¨¡å‹ï¼Œå…¶æ€§èƒ½å’Œç»“æ„ä¸åŸå§‹æ¨¡å‹ç›¸åŒï¼Œç”¨æˆ·å¯ä»¥å¯¹è½¬æ¢æ¨¡å‹è¿›è¡Œç®€å•é‡åŒ–ï¼Œä»¥è·å¾—ä¸ç‰¹å®šç®—æ³•é‡åŒ–æ¨¡å‹ç›¸åŒçš„æ€§èƒ½ã€‚
      save_trans: False
      # å¦‚æœ``save_lightllm`` æˆ–è€… ``save_trtllm`` ä¸º Trueï¼Œè¿™æ„å‘³ç€ä½ æƒ³è¦å¯¼å‡ºçœŸå®çš„é‡åŒ–æ¨¡å‹ï¼Œä¾‹å¦‚ï¼Œä½ä½æƒé‡å’Œæƒé‡åŠæ¿€æ´»é‡åŒ–å‚æ•°ã€‚
      save_lightllm: False
      # å¦‚æœ``save_fake``ä¸º Trueï¼Œæ„å‘³ç€ä½ æƒ³è¦å¯¼å‡ºå‡é‡åŒ–æ¨¡å‹ï¼Œä¾‹å¦‚ï¼Œå»é‡åŒ–çš„æƒé‡å’Œæ¿€æ´»é‡åŒ–å‚æ•°ã€‚
      save_fake: False
      save_path: ./save

  ```

- `quant`:

  ```yaml
  quant:
      # ç”¨``llmc/compression/quantization/*.py``ä¸­çš„ç±»åæ›¿æ¢ã€‚
      method: OmniQuant
      # ä»…æƒé‡é‡åŒ–æ²¡æœ‰``act``éƒ¨åˆ†ã€‚
      weight:
          bit: 8
          symmetric: True
          # é‡åŒ–ç²’åº¦ï¼šper_channel, per_tensor, per_headï¼ˆä¸æ¨èï¼‰ã€‚
          granularity: per_channel
          group_size: -1
          # æ ¡å‡†ç®—æ³•ï¼šlearnble, mse, ä»¥åŠ minmaxï¼ˆé»˜è®¤ï¼‰ã€‚
          calib_algo: learnable
          # ä½¿ç”¨ç›´é€šä¼°è®¡ï¼ˆStright-Through Estimationï¼‰ï¼Œè¿™å¯¹äºå¯å­¦ä¹ çš„æ ¡å‡†ç®—æ³•æ˜¯å¿…éœ€çš„ã€‚
          ste: True
      act:
          bit: 8
          symmetric: True
          # é‡åŒ–ç²’åº¦ï¼šper_token, per_tensor
          granularity: per_token
          ste: True
          # é™æ€é‡åŒ–ï¼ˆæ ¡å‡†æœŸé—´çš„é‡åŒ–ï¼‰æˆ–åŠ¨æ€é‡åŒ–ï¼ˆæ¨ç†æœŸé—´çš„é‡åŒ–ï¼‰ã€‚
          static: True
      # è¿™éƒ¨åˆ†æ˜¯ä¸ºç‰¹å®šç®—æ³•è®¾è®¡çš„ï¼Œç”¨æˆ·å¯ä»¥å‚è€ƒæˆ‘ä»¬æä¾›çš„ç®—æ³•æ¥è®¾è®¡ä»–ä»¬è‡ªå·±çš„ç®—æ³•ã€‚
      special:
          let: True
          lwc_lr: 0.01
          let_lr: 0.005
          use_shift: False
          alpha: 0.5
          deactive_amp: True
          epochs: 20
          wd: 0
      # å¦‚æœ quant_out ä¸º Trueï¼Œä½¿ç”¨å‰ä¸€ä¸ªé‡åŒ–å—çš„è¾“å‡ºä½œä¸ºåç»­å—çš„æ ¡å‡†æ•°æ®ã€‚
      quant_out: True

  ```

## æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨

âœ… [BLOOM](https://huggingface.co/bigscience/bloom)

âœ… [LLaMA](https://github.com/facebookresearch/llama)

âœ… [LLaMA V2](https://huggingface.co/meta-llama)

âœ… [StarCoder](https://github.com/bigcode-project/starcoder)

âœ… [OPT](https://huggingface.co/docs/transformers/model_doc/opt)

âœ… [Falcon](https://huggingface.co/docs/transformers/model_doc/falcon)

âœ… [InternLM2](https://huggingface.co/internlm)

âœ… [Mistral](https://huggingface.co/docs/transformers/model_doc/mistral)

âœ… [LLaMA V3](https://huggingface.co/meta-llama)

âœ… [Mixtral](https://huggingface.co/docs/transformers/model_doc/mixtral)

âœ… [Qwen V2](https://github.com/QwenLM/Qwen2)

âœ… [LLaVA](https://github.com/haotian-liu/LLaVA)

âœ… [InternLM2.5](https://huggingface.co/internlm)

âœ… [StableLM](https://github.com/Stability-AI/StableLM)

âœ… [Gemma2](https://huggingface.co/docs/transformers/main/en/model_doc/gemma2)

âœ… [Phi2](https://huggingface.co/microsoft/phi-2)

âœ… [Phi 1.5](https://huggingface.co/microsoft/phi-1_5)

âœ… [MiniCPM](https://github.com/OpenBMB/MiniCPM)

âœ… [SmolLM](https://huggingface.co/collections/HuggingFaceTB/smollm-6695016cad7167254ce15966)

ä½ å¯ä»¥å‚è€ƒ `llmc/models/*.py` ä¸‹çš„æ–‡ä»¶æ·»åŠ ä½ è‡ªå·±çš„æ¨¡å‹ç±»å‹ã€‚

## æ”¯æŒçš„ç®—æ³•åˆ—è¡¨

### é‡åŒ–

âœ… Naive

âœ… [AWQ](https://arxiv.org/abs/2306.00978)

âœ… [GPTQ](https://arxiv.org/abs/2210.17323)

âœ… [SmoothQuant](https://arxiv.org/abs/2211.10438)

âœ… [OS+](https://arxiv.org/abs/2304.09145)

âœ… [OmniQuant](https://arxiv.org/abs/2308.13137)

âœ… [NormTweaking](https://arxiv.org/abs/2309.02784)

âœ… [AdaDim](https://arxiv.org/pdf/2309.15531.pdf)

âœ… [QUIK](https://arxiv.org/abs/2310.09259)

âœ… [SpQR](https://arxiv.org/abs/2306.03078)

âœ… [DGQ](https://arxiv.org/abs/2310.04836)

âœ… [OWQ](https://arxiv.org/abs/2306.02272)

âœ… [LLM.int8()](https://arxiv.org/abs/2208.07339)

âœ… [HQQ](https://mobiusml.github.io/hqq_blog/)

âœ… [QuaRot](https://arxiv.org/abs/2404.00456)

### å‰ªæ

âœ… Naive(Magnitude)

âœ… [Wanda](https://arxiv.org/abs/2306.11695)

âœ… [ShortGPT](https://arxiv.org/abs/2403.03853)

## è‡´è°¢

æˆ‘ä»¬çš„ä»£ç å‚è€ƒäº†ä»¥ä¸‹ä»“åº“ï¼š

- https://github.com/mit-han-lab/llm-awq
- https://github.com/mit-han-lab/smoothquant
- https://github.com/OpenGVLab/OmniQuant
- https://github.com/IST-DASLab/gptq
- https://github.com/ModelTC/Outlier_Suppression_Plus
- https://github.com/IST-DASLab/QUIK
- https://github.com/Vahe1994/SpQR
- https://github.com/ilur98/DGQ
- https://github.com/xvyaward/owq
- https://github.com/TimDettmers/bitsandbytes
- https://github.com/mobiusml/hqq
- [https://github.com/locuslab/wanda](https://github.com/locuslab/wanda)
- [https://github.com/EleutherAI/lm-evaluation-harness](https://github.com/EleutherAI/lm-evaluation-harness)

